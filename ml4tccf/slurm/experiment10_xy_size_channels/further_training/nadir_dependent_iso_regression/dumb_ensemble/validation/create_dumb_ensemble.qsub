#!/bin/tcsh

#SBATCH --job-name="create_dumb_ensemble"
#SBATCH --partition="fge"
#SBATCH --account="rda-ghpcs"
#SBATCH --qos="batch"
#SBATCH --ntasks=1
#SBATCH --nodes=1
#SBATCH --cpus-per-task=1
##SBATCH --nodes=1
##SBATCH --ntasks=1
##SBATCH --cpus-per-task=1
##SBATCH --ntasks-per-node=1
#SBATCH --time=30:00:00
#SBATCH --exclude=h28n12
##SBATCH --exclude=h31n03,h28n12
##SBATCH --exclude=h29n01,h26n05,h28n06,h29n07,h30n03,h30n15
#SBATCH --mail-type=BEGIN,END,FAIL
#SBATCH --mail-user=ryan.lagerquist@noaa.gov
#SBATCH --output=create_dumb_ensemble_%A.out

module load cuda/10.1
source /scratch2/BMC/gsd-hpcs/Jebb.Q.Stewart/conda3.7/etc/profile.d/conda.csh
conda activate base

set CODE_DIR_NAME="/scratch1/RDARCH/rda-ghpcs/Ryan.Lagerquist/ml4tccf_standalone/ml4tccf"
set TOP_MODEL_DIR_NAME="/scratch1/RDARCH/rda-ghpcs/Ryan.Lagerquist/ml4tccf_models/experiment10_xy_size_channels/further_training"
set OUTPUT_DIR_NAME="${TOP_MODEL_DIR_NAME}/dumb_ensemble"

set GRID_ROW_COUNTS=("300" "300" "300" "300" "400" "400" "400" "400" "500" "500" "500" "500" "590" "590" "590" "590" "300" "300" "300" "300" "400" "400" "400" "400" "500" "500" "500" "500" "590" "590" "590" "590" "300" "300" "300" "300" "400" "400" "400" "400" "500" "500" "500" "500" "590" "590" "590" "590" "300" "300" "300" "300" "400" "400" "400" "400" "500" "500" "500" "500" "590" "590" "590" "590" "300" "300" "300" "300" "400" "400" "400" "400" "500" "500" "500" "500" "590" "590" "590" "590")
set LAG_TIME_COUNTS=("3" "3" "3" "3" "3" "3" "3" "3" "3" "3" "3" "3" "3" "3" "3" "3" "4" "4" "4" "4" "4" "4" "4" "4" "4" "4" "4" "4" "4" "4" "4" "4" "5" "5" "5" "5" "5" "5" "5" "5" "5" "5" "5" "5" "5" "5" "5" "5" "6" "6" "6" "6" "6" "6" "6" "6" "6" "6" "6" "6" "6" "6" "6" "6" "7" "7" "7" "7" "7" "7" "7" "7" "7" "7" "7" "7" "7" "7" "7" "7")
set FIRST_LAYER_FILTER_COUNTS=("10" "20" "30" "40" "10" "20" "30" "40" "10" "20" "30" "40" "10" "20" "30" "40" "10" "20" "30" "40" "10" "20" "30" "40" "10" "20" "30" "40" "10" "20" "30" "40" "10" "20" "30" "40" "10" "20" "30" "40" "10" "20" "30" "40" "10" "20" "30" "40" "10" "20" "30" "40" "10" "20" "30" "40" "10" "20" "30" "40" "10" "20" "30" "40" "10" "20" "30" "40" "10" "20" "30" "40" "10" "20" "30" "40" "10" "20" "30" "40")


set BEST_MODEL_INDICES=(8 19 39 54)

set CYCLONE_ID_STRINGS=("2021AL01" "2021AL02" "2021AL03" "2021AL04" "2021AL05" "2021AL06" "2021AL07" "2021AL08" "2021AL09" "2021AL10" "2021AL11" "2021AL12" "2021AL13" "2021AL14" "2021AL15" "2021AL16" "2021AL17" "2021AL18" "2021AL19" "2021EP01" "2021EP02" "2021EP03" "2021EP04" "2021EP05" "2021EP06" "2021EP07" "2021EP08" "2021EP09" "2021EP10" "2021EP11" "2021EP12" "2021EP13" "2021EP14" "2021EP15" "2021EP16" "2021EP17" "2021EP18" "2021EP19" "2021WP01" "2021WP02" "2021WP03" "2021WP04" "2021WP05" "2021WP06" "2021WP07" "2021WP08" "2021WP09" "2021WP10" "2021WP11" "2021WP12" "2021WP13" "2021WP14" "2021WP15" "2021WP16" "2021WP17" "2021WP18" "2021WP19" "2021WP20" "2021WP21" "2021WP22" "2021WP23" "2021WP24" "2021WP25" "2021WP26" "2021WP27" "2021WP28" "2021WP29")
set i=1

while ($i <= ${#CYCLONE_ID_STRINGS})
    set input_file_names_string=""
    set j=1
    
    while ($j <= ${#BEST_MODEL_INDICES})
        set best_model_index=${BEST_MODEL_INDICES[$j]}
    
        set num_first_layer_filters=${FIRST_LAYER_FILTER_COUNTS[$best_model_index]}
        set wavelength_group_string_microns=${WAVELENGTH_GROUP_STRINGS_MICRONS[$best_model_index]}
        set num_batches_per_epoch=${BATCHES_PER_EPOCH_COUNTS[$best_model_index]}
        set use_xy_flag=${USE_XY_FLAGS[$best_model_index]}
        
        set input_file_names_string="${input_file_names_string} ${TOP_MODEL_DIR_NAME}/wavelengths-microns=${wavelength_group_string_microns}_num-first-layer-filters=${num_first_layer_filters}_use-xy-coords=${use_xy_flag}_num-batches-per-epoch=${num_batches_per_epoch}/nadir_dependent_iso_regression/validation/with_random_seed/predictions_${CYCLONE_ID_STRINGS[$i]}.nc"
        @ j = $j + 1
    end
    
    python3 -u "${CODE_DIR_NAME}/create_multimodel_ensemble.py" \
    --input_prediction_file_names ${input_file_names_string} \
    --max_total_ensemble_size=200 \
    --output_prediction_file_name="${OUTPUT_DIR_NAME}/nadir_dependent_iso_regression/validation/predictions_${CYCLONE_ID_STRINGS[$i]}.nc"

    @ i = $i + 1
end
