#!/bin/tcsh

#SBATCH --job-name="convert_gridded_predictions_to_scalar"
#SBATCH --partition="fge"
#SBATCH --account="rda-ghpcs"
#SBATCH --qos="batch"
#SBATCH --ntasks=1
#SBATCH --nodes=1
#SBATCH --cpus-per-task=1
##SBATCH --nodes=1
##SBATCH --ntasks=1
##SBATCH --cpus-per-task=1
##SBATCH --ntasks-per-node=1
#SBATCH --time=30:00:00
#SBATCH --array=1,2,8,13,20,21,30,48,72
#SBATCH --exclude=h28n12
##SBATCH --exclude=h31n03,h28n12
##SBATCH --exclude=h29n01,h26n05,h28n06,h29n07,h30n03,h30n15
#SBATCH --mail-type=BEGIN,END,FAIL
#SBATCH --mail-user=ryan.lagerquist@noaa.gov
#SBATCH --output=convert_gridded_predictions_to_scalar_%A_%a.out

module load cuda/10.1
source /scratch2/BMC/gsd-hpcs/Jebb.Q.Stewart/conda3.7/etc/profile.d/conda.csh
conda activate base

set CODE_DIR_NAME="/scratch1/RDARCH/rda-ghpcs/Ryan.Lagerquist/ml4tccf_standalone/ml4tccf"
set TOP_MODEL_DIR_NAME="/scratch1/RDARCH/rda-ghpcs/Ryan.Lagerquist/ml4tccf_models/semantic_segmentation_experiment01"
set VALIDATION_DIR_NAME="/scratch1/RDARCH/rda-ghpcs/Ryan.Lagerquist/ml4tccf_project/satellite_data/processed/normalized_params_from_2017-2019"

set LAG_TIME_COUNTS=("01" "01" "01" "01" "02" "02" "02" "02" "04" "04" "04" "04" "06" "06" "06" "06" "08" "08" "08" "08" "10" "10" "10" "10" "12" "12" "12" "12" "01" "01" "01" "01" "02" "02" "02" "02" "04" "04" "04" "04" "06" "06" "06" "06" "08" "08" "08" "08" "10" "10" "10" "10" "12" "12" "12" "12" "01" "01" "01" "01" "02" "02" "02" "02" "04" "04" "04" "04" "06" "06" "06" "06" "08" "08" "08" "08" "10" "10" "10" "10" "12" "12" "12" "12")
set LOSS_FUNCTION_SCORE_NAMES=("fss" "fss" "fss" "fss" "fss" "fss" "fss" "fss" "fss" "fss" "fss" "fss" "fss" "fss" "fss" "fss" "fss" "fss" "fss" "fss" "fss" "fss" "fss" "fss" "fss" "fss" "fss" "fss" "gerrity" "gerrity" "gerrity" "gerrity" "gerrity" "gerrity" "gerrity" "gerrity" "gerrity" "gerrity" "gerrity" "gerrity" "gerrity" "gerrity" "gerrity" "gerrity" "gerrity" "gerrity" "gerrity" "gerrity" "gerrity" "gerrity" "gerrity" "gerrity" "gerrity" "gerrity" "gerrity" "gerrity" "brier" "brier" "brier" "brier" "brier" "brier" "brier" "brier" "brier" "brier" "brier" "brier" "brier" "brier" "brier" "brier" "brier" "brier" "brier" "brier" "brier" "brier" "brier" "brier" "brier" "brier" "brier" "brier")
set LOSS_FUNCTION_NEIGH_SIZES_PX=("3" "5" "7" "9" "3" "5" "7" "9" "3" "5" "7" "9" "3" "5" "7" "9" "3" "5" "7" "9" "3" "5" "7" "9" "3" "5" "7" "9" "3" "5" "7" "9" "3" "5" "7" "9" "3" "5" "7" "9" "3" "5" "7" "9" "3" "5" "7" "9" "3" "5" "7" "9" "3" "5" "7" "9" "3" "5" "7" "9" "3" "5" "7" "9" "3" "5" "7" "9" "3" "5" "7" "9" "3" "5" "7" "9" "3" "5" "7" "9" "3" "5" "7" "9")

set lag_time_count=${LAG_TIME_COUNTS[$SLURM_ARRAY_TASK_ID]}
set loss_function_score_name=${LOSS_FUNCTION_SCORE_NAMES[$SLURM_ARRAY_TASK_ID]}
set loss_function_neigh_size_px=${LOSS_FUNCTION_NEIGH_SIZES_PX[$SLURM_ARRAY_TASK_ID]}

set model_dir_name="${TOP_MODEL_DIR_NAME}/num-lag-times=${lag_time_count}_loss=${loss_function_score_name}${loss_function_neigh_size_px}"
echo $model_dir_name

set CYCLONE_ID_STRINGS=("2020AL13" "2020AL01" "2020AL02" "2020AL03" "2020AL04" "2020AL05" "2020AL06" "2020AL07" "2020AL08" "2020AL09" "2020AL10" "2020AL11" "2020AL12" "2020AL14" "2020AL15" "2020AL16" "2020AL17" "2020AL18" "2020AL19" "2020AL20" "2020AL21" "2020AL22" "2020AL23" "2020AL24" "2020AL25" "2020AL26" "2020AL27" "2020AL28" "2020AL29" "2020AL30" "2020AL31")
set i=1

while ($i <= ${#CYCLONE_ID_STRINGS})
    python3 -u "${CODE_DIR_NAME}/convert_gridded_predictions_to_scalar.py" \
    --input_prediction_file_name="${model_dir_name}/validation/predictions_${CYCLONE_ID_STRINGS[$i]}.nc" \
    --output_prediction_dir_name="${model_dir_name}/validation/scalar"

    @ i = $i + 1
end
