#!/bin/tcsh

#SBATCH --job-name="train_neural_nets"
#SBATCH --partition="fge"
#SBATCH --account="rda-ghpcs"
#SBATCH --qos="batch"
#SBATCH --nodes=1
#SBATCH --ntasks=8           # 8 tasks per node
#SBATCH --cpus-per-task=2
#SBATCH --ntasks-per-node=8  # 8 GPUs per node
#SBATCH --exclusive
#SBATCH --time=30:00:00
#SBATCH --array=1-84
#SBATCH --exclude=h28n12
##SBATCH --exclude=h31n03,h28n12
##SBATCH --exclude=h29n01,h26n05,h28n06,h29n07,h30n03,h30n15
#SBATCH --mail-type=BEGIN,END,FAIL
#SBATCH --mail-user=ryan.lagerquist@noaa.gov
#SBATCH --output=train_neural_nets_%A_%a.out

module load cuda/10.1
source /scratch2/BMC/gsd-hpcs/Jebb.Q.Stewart/conda3.7/etc/profile.d/conda.csh
conda activate base

set CODE_DIR_NAME="/scratch1/RDARCH/rda-ghpcs/Ryan.Lagerquist/ml4tccf_standalone/ml4tccf"
set TEMPLATE_DIR_NAME="/scratch1/RDARCH/rda-ghpcs/Ryan.Lagerquist/ml4tccf_models/semantic_segmentation_experiment01/templates"
set TOP_OUTPUT_DIR_NAME="/scratch1/RDARCH/rda-ghpcs/Ryan.Lagerquist/ml4tccf_models/semantic_segmentation_experiment01"

set TRAINING_DIR_NAME="/scratch1/RDARCH/rda-ghpcs/Ryan.Lagerquist/ml4tccf_project/satellite_data/processed/normalized_params_from_2017-2019"
set VALIDATION_DIR_NAME="${TRAINING_DIR_NAME}"

set LAG_TIME_COUNTS=("01" "01" "01" "01" "02" "02" "02" "02" "04" "04" "04" "04" "06" "06" "06" "06" "08" "08" "08" "08" "10" "10" "10" "10" "12" "12" "12" "12" "01" "01" "01" "01" "02" "02" "02" "02" "04" "04" "04" "04" "06" "06" "06" "06" "08" "08" "08" "08" "10" "10" "10" "10" "12" "12" "12" "12" "01" "01" "01" "01" "02" "02" "02" "02" "04" "04" "04" "04" "06" "06" "06" "06" "08" "08" "08" "08" "10" "10" "10" "10" "12" "12" "12" "12")
set LAG_TIME_STRINGS_MINUTES=("0" "0" "0" "0" "0-30" "0-30" "0-30" "0-30" "0-30-60-90" "0-30-60-90" "0-30-60-90" "0-30-60-90" "0-30-60-90-120-150" "0-30-60-90-120-150" "0-30-60-90-120-150" "0-30-60-90-120-150" "0-30-60-90-120-150-180-210" "0-30-60-90-120-150-180-210" "0-30-60-90-120-150-180-210" "0-30-60-90-120-150-180-210" "0-30-60-90-120-150-180-210-240-270" "0-30-60-90-120-150-180-210-240-270" "0-30-60-90-120-150-180-210-240-270" "0-30-60-90-120-150-180-210-240-270" "0-30-60-90-120-150-180-210-240-270-300-330" "0-30-60-90-120-150-180-210-240-270-300-330" "0-30-60-90-120-150-180-210-240-270-300-330" "0-30-60-90-120-150-180-210-240-270-300-330" "0" "0" "0" "0" "0-30" "0-30" "0-30" "0-30" "0-30-60-90" "0-30-60-90" "0-30-60-90" "0-30-60-90" "0-30-60-90-120-150" "0-30-60-90-120-150" "0-30-60-90-120-150" "0-30-60-90-120-150" "0-30-60-90-120-150-180-210" "0-30-60-90-120-150-180-210" "0-30-60-90-120-150-180-210" "0-30-60-90-120-150-180-210" "0-30-60-90-120-150-180-210-240-270" "0-30-60-90-120-150-180-210-240-270" "0-30-60-90-120-150-180-210-240-270" "0-30-60-90-120-150-180-210-240-270" "0-30-60-90-120-150-180-210-240-270-300-330" "0-30-60-90-120-150-180-210-240-270-300-330" "0-30-60-90-120-150-180-210-240-270-300-330" "0-30-60-90-120-150-180-210-240-270-300-330" "0" "0" "0" "0" "0-30" "0-30" "0-30" "0-30" "0-30-60-90" "0-30-60-90" "0-30-60-90" "0-30-60-90" "0-30-60-90-120-150" "0-30-60-90-120-150" "0-30-60-90-120-150" "0-30-60-90-120-150" "0-30-60-90-120-150-180-210" "0-30-60-90-120-150-180-210" "0-30-60-90-120-150-180-210" "0-30-60-90-120-150-180-210" "0-30-60-90-120-150-180-210-240-270" "0-30-60-90-120-150-180-210-240-270" "0-30-60-90-120-150-180-210-240-270" "0-30-60-90-120-150-180-210-240-270" "0-30-60-90-120-150-180-210-240-270-300-330" "0-30-60-90-120-150-180-210-240-270-300-330" "0-30-60-90-120-150-180-210-240-270-300-330" "0-30-60-90-120-150-180-210-240-270-300-330")
set LOSS_FUNCTION_SCORE_NAMES=("fss" "fss" "fss" "fss" "fss" "fss" "fss" "fss" "fss" "fss" "fss" "fss" "fss" "fss" "fss" "fss" "fss" "fss" "fss" "fss" "fss" "fss" "fss" "fss" "fss" "fss" "fss" "fss" "gerrity" "gerrity" "gerrity" "gerrity" "gerrity" "gerrity" "gerrity" "gerrity" "gerrity" "gerrity" "gerrity" "gerrity" "gerrity" "gerrity" "gerrity" "gerrity" "gerrity" "gerrity" "gerrity" "gerrity" "gerrity" "gerrity" "gerrity" "gerrity" "gerrity" "gerrity" "gerrity" "gerrity" "brier" "brier" "brier" "brier" "brier" "brier" "brier" "brier" "brier" "brier" "brier" "brier" "brier" "brier" "brier" "brier" "brier" "brier" "brier" "brier" "brier" "brier" "brier" "brier" "brier" "brier" "brier" "brier")
set LOSS_FUNCTION_NEIGH_SIZES_PX=("3" "5" "7" "9" "3" "5" "7" "9" "3" "5" "7" "9" "3" "5" "7" "9" "3" "5" "7" "9" "3" "5" "7" "9" "3" "5" "7" "9" "3" "5" "7" "9" "3" "5" "7" "9" "3" "5" "7" "9" "3" "5" "7" "9" "3" "5" "7" "9" "3" "5" "7" "9" "3" "5" "7" "9" "3" "5" "7" "9" "3" "5" "7" "9" "3" "5" "7" "9" "3" "5" "7" "9" "3" "5" "7" "9" "3" "5" "7" "9" "3" "5" "7" "9")

set lag_time_count=${LAG_TIME_COUNTS[$SLURM_ARRAY_TASK_ID]}
set lag_time_string_minutes=${LAG_TIME_STRINGS_MINUTES[$SLURM_ARRAY_TASK_ID]}
set loss_function_score_name=${LOSS_FUNCTION_SCORE_NAMES[$SLURM_ARRAY_TASK_ID]}
set loss_function_neigh_size_px=${LOSS_FUNCTION_NEIGH_SIZES_PX[$SLURM_ARRAY_TASK_ID]}
set lag_time_string_minutes="$lag_time_string_minutes:gas/-/ /"

set template_file_name="${TEMPLATE_DIR_NAME}/num-lag-times=${lag_time_count}_loss=${loss_function_score_name}${loss_function_neigh_size_px}/model.h5"
set output_dir_name="${TOP_OUTPUT_DIR_NAME}/num-lag-times=${lag_time_count}_loss=${loss_function_score_name}${loss_function_neigh_size_px}"
echo $output_dir_name

python3 -u "${CODE_DIR_NAME}/train_neural_net.py" \
--input_template_file_name="${template_file_name}" \
--output_model_dir_name="${output_dir_name}" \
--lag_times_minutes ${lag_time_string_minutes} \
--num_examples_per_batch=8 \
--max_examples_per_cyclone=1 \
--num_rows_low_res=600 \
--num_columns_low_res=600 \
--low_res_wavelengths_microns 11.2 \
--data_aug_num_translations=4 \
--data_aug_mean_translation_low_res_px=22.5 \
--data_aug_stdev_translation_low_res_px=11.25 \
--sentinel_value=-10 \
--target_smoother_stdev_km=0.000001 \
--lag_time_tolerance_for_training_sec=910 \
--max_num_missing_lag_times_for_training=1 \
--max_interp_gap_for_training_sec=3610 \
--satellite_dir_name_for_training="${TRAINING_DIR_NAME}" \
--training_years 2017 2018 2019 \
--lag_time_tolerance_for_validation_sec=910 \
--max_num_missing_lag_times_for_validation=1 \
--max_interp_gap_for_validation_sec=3610 \
--satellite_dir_name_for_validation="${VALIDATION_DIR_NAME}" \
--validation_years 2020 \
--num_epochs=1000 \
--num_training_batches_per_epoch=32 \
--num_validation_batches_per_epoch=16
