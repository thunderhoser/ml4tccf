#!/bin/bash

#SBATCH --job-name="apply_neural_nets"
#SBATCH --partition="fge"
#SBATCH --account="rda-ghpcs"
#SBATCH --qos="gpuwf"
#SBATCH --ntasks=1
#SBATCH --nodes=1
#SBATCH --cpus-per-task=1
##SBATCH --nodes=1
##SBATCH --ntasks=1
##SBATCH --cpus-per-task=1
##SBATCH --ntasks-per-node=1
#SBATCH --time=24:00:00
#SBATCH --array=0-59
#SBATCH --exclude=h28n12
##SBATCH --exclude=h31n03,h28n12
##SBATCH --exclude=h29n01,h26n05,h28n06,h29n07,h30n03,h30n15
#SBATCH --mail-type=BEGIN,END,FAIL
#SBATCH --mail-user=ryan.lagerquist@noaa.gov
#SBATCH --output=apply_neural_nets_%A_%a.out

module load cuda/12.3.1
conda init
conda activate base

echo `which conda`
echo `which python`
echo `which python3`

# PATH=/usr/local/cuda/bin:$PATH
echo $PATH

CODE_DIR_NAME="/scratch1/RDARCH/rda-ghpcs/Ryan.Lagerquist/ml4tccf_standalone/ml4tccf"
TOP_MODEL_DIR_NAME="/scratch1/RDARCH/rda-ghpcs/Ryan.Lagerquist/ml4tccf_models/paper_experiment05_domain_video_distribution/ensemble"
EXAMPLE_DIR_NAME="/scratch1/RDARCH/rda-ghpcs/Ryan.Lagerquist/ml4tccf_project/satellite_data/processed/normalized_for_paper/900x900_grids/testing"
A_DECK_FILE_NAME="/scratch1/RDARCH/rda-ghpcs/Ryan.Lagerquist/ml4tccf_project/a_decks/processed/a_decks_normalized.nc"

TRANSLATION_DISTANCES_PX=("001" "002" "003" "004" "005" "006" "007" "008" "009" "010" "011" "012" "013" "014" "015" "016" "017" "018" "019" "020" "021" "022" "023" "024" "025" "026" "027" "028" "029" "030" "031" "032" "033" "034" "035" "036" "037" "038" "039" "040" "041" "042" "043" "044" "045" "046" "047" "048" "049" "050" "051" "052" "053" "054" "055" "056" "057" "058" "059" "060")

CYCLONE_ID_STRINGS=("2022EP14" "2021AL06" "2022EP09" "2021AL02" "2022EP10" "2021WP20" "2021WP16" "2021AL12" "2021AL07" "2021WP03" "2021WP04" "2021WP06" "2022EP16" "2021WP11" "2021WP19" "2021WP15" "2022EP05" "2021WP17" "2022EP11" "2021AL19")
WAVELENGTH_GROUP_STRINGS_MICRONS=("8.500-9.610-12.300" "3.900-7.340-13.300" "3.900-6.185-6.950" "6.950-10.350-11.200")

i=0

while [ $i -lt ${#CYCLONE_ID_STRINGS[@]} ]; do
    j=0
    
    while [ $j -lt ${#WAVELENGTH_GROUP_STRINGS_MICRONS[@]} ]; do
        wavelength_group_string_microns=${WAVELENGTH_GROUP_STRINGS_MICRONS[$j]}
        model_dir_name="${TOP_MODEL_DIR_NAME}/wavelengths-microns=${wavelength_group_string_microns}"
        echo $model_dir_name
        
        python3 -u "${CODE_DIR_NAME}/apply_neural_net.py" \
        --input_model_file_name="${model_dir_name}/model.weights.h5" \
        --input_satellite_dir_name="${EXAMPLE_DIR_NAME}" \
        --input_a_deck_file="${A_DECK_FILE_NAME}" \
        --cyclone_id_string="${CYCLONE_ID_STRINGS[$i]}" \
        --data_aug_num_translations=8 \
        --data_aug_mean_translation_low_res_px=${TRANSLATION_DISTANCES_PX[$SLURM_ARRAY_TASK_ID]} \
        --data_aug_stdev_translation_low_res_px=0.000001 \
        --data_aug_uniform_dist_flag=0 \
        --random_seed=6695 \
        --remove_tropical_systems=0 \
        --synoptic_times_only=1 \
        --output_dir_name="${model_dir_name}/sensitivity_analysis_to_trans_dist/translation_distance_px=${TRANSLATION_DISTANCES_PX[$SLURM_ARRAY_TASK_ID]}"
    
        j=$(( $j + 1 ))
    done
    
    i=$(( $i + 1 ))
done
