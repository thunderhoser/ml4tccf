#!/bin/tcsh

#SBATCH --job-name="evaluate_neural_nets"
#SBATCH --partition="fge"
#SBATCH --account="rda-ghpcs"
#SBATCH --qos="batch"
#SBATCH --nodes=1
#SBATCH --ntasks=8           # 8 tasks per node
#SBATCH --cpus-per-task=2
#SBATCH --ntasks-per-node=8  # 8 GPUs per node
#SBATCH --exclusive
#SBATCH --time=06:00:00
#SBATCH --array=1-4
#SBATCH --exclude=h28n12
##SBATCH --exclude=h31n03,h28n12
##SBATCH --exclude=h29n01,h26n05,h28n06,h29n07,h30n03,h30n15
#SBATCH --mail-type=BEGIN,END,FAIL
#SBATCH --mail-user=ryan.lagerquist@noaa.gov
#SBATCH --output=evaluate_neural_nets_%A_%a.out

module load cuda/10.1
source /scratch2/BMC/gsd-hpcs/Jebb.Q.Stewart/conda3.7/etc/profile.d/conda.csh
conda activate base

set CODE_DIR_NAME="/scratch1/RDARCH/rda-ghpcs/Ryan.Lagerquist/ml4tccf_standalone/ml4tccf"
set TOP_MODEL_DIR_NAME="/scratch1/RDARCH/rda-ghpcs/Ryan.Lagerquist/ml4tccf_models/intensity_experiment01/no_center_fixing_nn"

set FIRST_LAYER_FILTER_COUNTS=("16" "16" "32" "16")
set WAVELENGTH_GROUP_STRINGS_MICRONS=("8.500-9.610-12.300" "3.900-7.340-13.300" "3.900-6.185-6.950" "6.950-10.350-11.200")
set BATCHES_PER_EPOCH_COUNTS=("36" "24" "36" "24")
set BATCHES_PER_UPDATE_COUNTS=("2" "1" "1" "1")

set num_first_layer_filters=${FIRST_LAYER_FILTER_COUNTS[$SLURM_ARRAY_TASK_ID]}
set wavelength_group_string_microns=${WAVELENGTH_GROUP_STRINGS_MICRONS[$SLURM_ARRAY_TASK_ID]}
set num_batches_per_epoch=${BATCHES_PER_EPOCH_COUNTS[$SLURM_ARRAY_TASK_ID]}
set num_batches_per_update=${BATCHES_PER_UPDATE_COUNTS[$SLURM_ARRAY_TASK_ID]}

set model_dir_name="${TOP_MODEL_DIR_NAME}/wavelengths-microns=${wavelength_group_string_microns}_num-first-layer-filters=${num_first_layer_filters}_num-batches-per-epoch=${num_batches_per_epoch}_num-batches-per-update=${num_batches_per_update}"
echo $model_dir_name

python3 -u "${CODE_DIR_NAME}/evaluate_neural_net_intensity.py" \
--input_prediction_file_pattern="${model_dir_name}/validation/predictions*.nc" \
--output_dir_name="${model_dir_name}/validation/evaluation"
